{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DevOps Directive Site Load Testing\n",
    "\n",
    "Corresponding Post: https://devopsdirective.com/posts/2020/03/load-testing-f1-micro/\n",
    "\n",
    "---\n",
    "\n",
    "- Tested using [k6](https://k6.io)\n",
    "- Tests performed on n1-standard-4 ubuntu 16.04 instance\n",
    "- Tests performed with and without CloudFlare caching\n",
    "\n",
    "\n",
    "For each test run I want:\n",
    "- num vus\n",
    "- num iterations\n",
    "- num http reqs\n",
    "- check failures\n",
    "- data_received\n",
    "- **ALL** http_* stats [avg, min, med, 90, 95, max]\n",
    "\n",
    "---\n",
    "\n",
    "*NOTE:* I know you can save k6 output as a JSON file, but doing so saves all of the requests while I just wanted the summary usually printed to stdout. This meant I then had to do some text parsing in order to work with it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "\n",
    "import re\n",
    "from os import walk, path\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_files = []\n",
    "DIR_PATH = './results-n1-standard-8-60-second-tests'\n",
    "for (dirpath, dirnames, filenames) in walk(DIR_PATH):\n",
    "    for filename in sorted(filenames):\n",
    "        if filename[0] != '.':\n",
    "            result_files.append((filename, path.join(DIR_PATH, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the text files\n",
    "\n",
    "def parse_timestring_to_ms(t_string):\n",
    "    UNIT_PREFIX = re.compile('[^(n|µ|m|s)]*')\n",
    "    num = UNIT_PREFIX.search(t_string).group(0)\n",
    "    if num == t_string:\n",
    "        raise ValueError('No unit string found')\n",
    "    prefix = t_string[len(num)]\n",
    "    if prefix == 'n':\n",
    "        return float(num) / 1000000\n",
    "    elif prefix == 'µ':\n",
    "        return float(num) / 1000\n",
    "    elif prefix == 'm':\n",
    "        return float(num)\n",
    "    elif prefix == 's':\n",
    "        return float(num) * 1000\n",
    "    else:\n",
    "        raise ValueError('Unit did not match ns, µs, ms, or s')\n",
    "        \n",
    "def convert_datastrings_to_mb(num, unit):\n",
    "    if unit == 'MB':\n",
    "        return float(num)\n",
    "    elif unit == 'GB':\n",
    "        return float(num) * 1000\n",
    "    else:\n",
    "        raise ValueError('Unit did not equal MB or GB')\n",
    "\n",
    "def extract_results_dict(file_tuple):\n",
    "    result = {}\n",
    "    \n",
    "    PERCENTILES = ['avg', '0', '50', '100', '90', '95']\n",
    "    \n",
    "    FIELD = re.compile(r'(\\w+)\\.*:(.*)', re.DOTALL)  # split the line to name:value\n",
    "    VALUES = re.compile(r'(?<==).*?(?=\\s|$)')  # match individual values from http_req_* fields\n",
    "    result['cached'] = True if file_tuple[0].split('-')[1] == 'cache' else False\n",
    "    filepath = file_tuple[1]\n",
    "\n",
    "    # open the input file `k6_input.log` for reading, and k6_parsed.log` for parsing\n",
    "    with open(filepath, \"r\") as f_in:\n",
    "        for i, line in enumerate(f_in):  # read the input file line by line\n",
    "            if i < 25: # skip header content\n",
    "                continue\n",
    "            field = FIELD.match(line.strip())  # first match all <field_name>...:<values> fields\n",
    "            if field:\n",
    "                name = field.group(1)  # get the field name from the first capture group\n",
    "                value = field.group(2)  # get the field value from the second capture group\n",
    "                if name[:9] == \"http_req_\":\n",
    "                    http_req_ms = list(map(parse_timestring_to_ms, VALUES.findall(value)))\n",
    "                    for percentile, req_ms in zip(PERCENTILES, http_req_ms):\n",
    "                        result[f'{name}_{percentile}'] = req_ms\n",
    "                if name == 'check_failure_rate':\n",
    "                    line_split = line.split()\n",
    "                    valid_checks = line_split[-1]\n",
    "                    invalid_checks = line_split[-3]\n",
    "                    result['valid_checks'] = valid_checks\n",
    "                    result['invalid_checks'] = invalid_checks\n",
    "                    result['invalid_percentage'] = 100*int(invalid_checks)/(int(valid_checks) + int(invalid_checks))\n",
    "                if name in ['vus', 'iterations', 'http_reqs']:\n",
    "                    num = line.split()[1]\n",
    "                    result[name] = num\n",
    "                if name == 'data_received':\n",
    "                    line_split = line.split()\n",
    "                    num = line_split[1]\n",
    "                    unit = line_split[2]\n",
    "                    result[name] = convert_datastrings_to_mb(num, unit)\n",
    "    return result\n",
    "\n",
    "results = {}\n",
    "for file_tuple in result_files:\n",
    "    filename = file_tuple[0]\n",
    "    results[filename] = extract_results_dict(file_tuple)\n",
    "\n",
    "# Each result value is a dict shaped:\n",
    "# \n",
    "# {\n",
    "#     'cache': True,\n",
    "#     'valid_checks': '3794', \n",
    "#     'invalid_checks': '0', \n",
    "#     'data_received': 1700.0, \n",
    "#     'http_req_*_avg': 13.99\n",
    "#     'http_req_*_0': 13.99\n",
    "#     'http_req_*_50': 13.99\n",
    "#     'http_req_*_100': 13.99\n",
    "#     'http_req_*_90': 13.99\n",
    "#     'http_req_*_95': 13.99\n",
    "#     'http_reqs': '49709', \n",
    "#     'iterations': '3584', \n",
    "#     'vus': '1536'\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming into format for plotting\n",
    "\n",
    "cached = {}\n",
    "uncached = {}\n",
    "\n",
    "# initilize empty list values\n",
    "for key in results['0006-cache-summary.txt'].keys():\n",
    "    cached[key] = []\n",
    "    uncached[key] = []\n",
    "    \n",
    "for result in results.values():  \n",
    "    is_cached = result['cached']\n",
    "    for key, value in result.items():\n",
    "        if is_cached:\n",
    "            cached[key].append(value)\n",
    "        else:\n",
    "            uncached[key].append(value)\n",
    "\n",
    "cached_df = pd.DataFrame.from_dict(cached)\n",
    "uncached_df = pd.DataFrame.from_dict(uncached)\n",
    "\n",
    "uncached_without_failed_test_df = uncached_df.drop(uncached_df.tail(1).index)\n",
    "cached_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting\n",
    "def plot_timing_data(metric):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    cached_x = cached_df['vus']\n",
    "    uncached_x = uncached_df['vus']\n",
    "    \n",
    "    series_name = f'{metric}_50'\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cached_x, \n",
    "        y=cached_df[series_name],\n",
    "        name=f'Cached 50% (median)',\n",
    "        line=dict(color='limegreen', width=2, dash='dot')\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=uncached_x, \n",
    "        y=uncached_without_failed_test_df[series_name],\n",
    "        name=f'Uncached 50% (median)',\n",
    "        line=dict(color='limegreen', width=2)\n",
    "    ))\n",
    "\n",
    "    series_name = f'{metric}_90'\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cached_x, \n",
    "        y=cached_df[series_name],\n",
    "        name=f'Cached 90%',\n",
    "        line=dict(color='orange', width=2, dash='dot')\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=uncached_x, \n",
    "        y=uncached_without_failed_test_df[series_name],\n",
    "        name=f'Uncached 90%',\n",
    "        line=dict(color='orange', width=2)\n",
    "    ))\n",
    "\n",
    "    series_name = f'{metric}_95'\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cached_x, \n",
    "        y=cached_df[series_name],\n",
    "        name='Cached 95%',\n",
    "        line=dict(color='red', width=2, dash='dot')\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=uncached_x, \n",
    "        y=uncached_without_failed_test_df[series_name],\n",
    "        name='Uncached 95%',\n",
    "        line=dict(color='red', width=2)\n",
    "    ))\n",
    "\n",
    "    \n",
    "    \n",
    "    fig.update_layout(\n",
    "        title= f'{metric} vs. Number of Virtual Users',\n",
    "        xaxis_title='Virtual Users',\n",
    "        yaxis_title='Time (ms)',\n",
    "        width=1000, \n",
    "        height=450,\n",
    "        annotations=[\n",
    "                go.layout.Annotation(\n",
    "                    text=' <br>NOTE: 74% of virtual users in <br> final uncached test (excluded from <br> plot) never received a response, <br>  causing invalid timing results<br>  ',\n",
    "                    align='center',\n",
    "                    showarrow=False,\n",
    "                    x=1400,\n",
    "                    yref='paper',\n",
    "                    y=1,\n",
    "                    bordercolor='black',\n",
    "                    borderwidth=1\n",
    "                )\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "#     fig.write_image(f'{metric}.png')\n",
    "#     fig.write_html(f'{metric}.html')\n",
    "    return fig\n",
    "    \n",
    "fig = plot_timing_data('http_req_duration')\n",
    "# plotly.offline.plot(fig, filename = 'filename.html', auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_nontiming_data(metric, y_label):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    cached_x = cached_df['vus']\n",
    "    uncached_x = uncached_df['vus']\n",
    "\n",
    "    series_name = metric\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cached_x, \n",
    "        y=cached_df[series_name],\n",
    "        name=f'Cached',\n",
    "        line=dict(color='limegreen', width=2, dash='dot')\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cached_x, \n",
    "        y=uncached_without_failed_test_df[series_name],\n",
    "        name=f'Uncached',\n",
    "        line=dict(color='limegreen', width=2)\n",
    "    ))\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title= f'{series_name} vs. Number of Virtual Users',\n",
    "        xaxis_title='Virtual Users',\n",
    "        yaxis_title=y_label,\n",
    "        width=1000, \n",
    "        height=450,\n",
    "        annotations=[\n",
    "                go.layout.Annotation(\n",
    "                    text=' <br>NOTE: 74% of virtual users in <br> final uncached test (excluded from <br> plot) never received a response, <br> ',\n",
    "                    align='center',\n",
    "                    showarrow=False,\n",
    "                    x=1600,\n",
    "                    yref='paper',\n",
    "                    y=0,\n",
    "                    bordercolor='black',\n",
    "                    borderwidth=1\n",
    "                )\n",
    "            ]\n",
    "    )\n",
    "\n",
    "#     fig.write_image(f'{metric}.png')\n",
    "#     fig.write_html(f'{metric}.html')\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "fig = plot_nontiming_data('data_received', 'Data (MB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
